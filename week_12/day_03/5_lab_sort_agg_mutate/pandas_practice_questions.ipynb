{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Core-questions\" data-toc-modified-id=\"Core-questions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Core questions</a></span></li><li><span><a href=\"#Extension-questions\" data-toc-modified-id=\"Extension-questions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Extension questions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Let's load in the datasets we need for the practice session. They correspond to cuts of the tables from the `omni_pool` database we used earlier in the course. The idea in this session is to try to do in `pandas` some of the operations we coded in `SQL` (with a bit of variation to keep things fresh)!\n",
    "\n",
    "We would recommend you try all of the Core Questions below, and then move on to the Extension Questions if time permits.\n",
    "\n",
    "**Note** - some of the questions should be attempted only after you have covered the material on joining, melting and pivoting `DataFrame`s on day 3. We have marked these questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "employees = pd.read_csv('data/omni_employees.csv', parse_dates=['start_date'])\n",
    "pay_details = pd.read_csv('data/omni_pay_details.csv')\n",
    "teams = pd.read_csv('data/omni_teams.csv')\n",
    "committees = pd.read_csv('data/omni_committees.csv')\n",
    "employees_committees = pd.read_csv('data/omni_employees_committees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core questions\n",
    "\n",
    "***Q1.*** Perform some basic data exploration of the `employees` `DataFrame`. Methods and attributes to consider using here include `.info()`, `.describe()` and `.shape`. In particular, answer the following:\n",
    "\n",
    "- What data type is each column?\n",
    "- How many unique values are there in `department` and `country`?\n",
    "- What are the minimum and maximum of `salary`?\n",
    "- How many rows are there in the `DataFrame`?\n",
    "  \n",
    "***  \n",
    "  \n",
    "***Q2.*** Find all the details of `employees` who work in the 'Legal' `department`.\n",
    "\n",
    "***\n",
    "  \n",
    "***Q3.*** How many `employees` are based in Japan?  \n",
    "\n",
    "**Hint** - Running `.count()` on the `id` column might help here, or you could use the `.shape` attribute \n",
    "\n",
    "***\n",
    "\n",
    "***Q4.*** [**Harder**] In the question above, we suggested you `.count()` the `id` column (i.e. treating it like a `SQL` primary key). But we haven't yet shown that `id` satisfies the associated requirements. Confirm that the number of unique values in `id` equals the number of rows in `employees`.\n",
    "\n",
    "**Hints**\n",
    "\n",
    "* The `.shape` attribute of the `employees` `DataFrame` and the `.nunique()` method can be combined in one line of code to show this\n",
    "* Remember that `.shape` returns a `tuple`: which element of the `tuple` do you need?\n",
    "\n",
    "***\n",
    "\n",
    "***Q5.*** How many `employees` have a missing `email` address?\n",
    "\n",
    "***\n",
    "\n",
    "***Q6.*** Calculate the mean `salary` of `employees` in the 'Legal' `department`.\n",
    "\n",
    "***\n",
    "\n",
    "***Q7.*** Obtain the `first_name`, `last_name` and `salary` of all `employees` sorted in descending order of `salary`.\n",
    "\n",
    "***\n",
    "\n",
    "***Q8.*** Obtain the `first_name`, `last_name` and `country` of `employees` ordered first alphabetically by `country` and then alphabetically by `last_name`.\n",
    "\n",
    "***\n",
    "\n",
    "***Q9.*** [**Harder**] Obtain the `first_name`, `last_name` and `email` address of all `employees` in the 'Engineering' `department` who work 0.5 `fte_hours` or greater.\n",
    "\n",
    "***\n",
    "\n",
    "***Q10.*** [**Harder**] Calculate the mean `salary` of all `employees` who are members either of the 'Legal' or the 'Accounting' `department`s.\n",
    "\n",
    "**Hint** - The `.isin()` method let's you do this in one line of code, without having to manually combine means for the two `department`s\n",
    "   \n",
    "***\n",
    "    \n",
    "***Q11.*** [**Harder**] How many pension enrolled `employees` are based outside of France, Austria or Ireland?\n",
    "\n",
    "**Hint** - Remember `~` is the negation operator in `pandas`\n",
    "\n",
    "***\n",
    "    \n",
    "***Q12.*** Add a new column `effective_salary` to `employees` containing `salary` multiplied by `fte_hours`.\n",
    "\n",
    "***\n",
    "\n",
    "    \n",
    "***Q13.*** Obtain a table showing the number of `employees` in each `department`.\n",
    "\n",
    "**Hint** - Think **split-apply-combine** \n",
    "\n",
    "***\n",
    "\n",
    "***Q14.*** Obtain a count of the number of `employees` enrolled and not enrolled in the pension scheme. Ignore missing values in `pension_enrol` for now.\n",
    "\n",
    "***\n",
    "\n",
    "***Q15.*** [**Harder**] Repeat your analysis from Question 17 above, but this time fill any missing values in `pension_enrol` with the string 'Missing'.\n",
    "\n",
    "**Hint** - the `.fillna()` method will help here\n",
    "\n",
    "***\n",
    "\n",
    "***Q16.*** Obtain a count by `department` of the number of `employees` enrolled and not enrolled in the pension scheme. Include missing values or otherwise fill them with the string 'Missing' as in the question above. [**Harder**] - Change the header of the column containing count values to 'num_employees'.\n",
    "\n",
    "**Hints** \n",
    "\n",
    "* You need to `.groupby()` on multiple columns\n",
    "* Is there an argument to `.groupby()` that lets you keep missing values?\n",
    "* The `.agg()` method can take arguments that let you specify the output column name for an aggregator\n",
    "\n",
    "***\n",
    "    \n",
    "***Q17.*** Obtain a table showing all `employees` details together with a column `team_name` containing the name of their team. \n",
    "\n",
    "**Attempt this question only after the lesson on joining, melting and pivoting `DataFrame`s on day 3**\n",
    "\n",
    "**Hints**\n",
    "\n",
    "* This will require joining `employees` to `teams`\n",
    "* You can `.drop()` unwanted columns from `teams` after the join\n",
    "* The `.rename()` method lets you change column names\n",
    "\n",
    "***\n",
    "    \n",
    "***Q18.*** [**Harder**] Obtain a table showing `team_name` together with a count of the `num_employees` in each team.\n",
    "\n",
    "**Attempt this question only after the lesson on joining, melting and pivoting `DataFrame`s on day 3**\n",
    "\n",
    "**Hints**\n",
    "    \n",
    "* You will need to join `employees` to `teams`\n",
    "* The `.rename()` method lets you rename a column\n",
    "* The `.agg()` method can take arguments that let you specify the output column name for an aggregator    \n",
    "\n",
    "***\n",
    "\n",
    "***Q19.*** [**Harder**] Obtain a table showing the `id`, `first_name`, `last_name` and `department` of any `employees` lacking both a `local_account_no` and `local_sort_code` in their `pay_details`.\n",
    "\n",
    "**Attempt this question only after the lesson on joining, melting and pivoting `DataFrame`s on day 3**\n",
    "\n",
    "**Hints**\n",
    "    \n",
    "* Filter `pay_details` down to those rows lacking both a `local_account_no` and `local_sort_code`, and then join that to `employees`\n",
    "* The `.all()` method applied over columns can help here\n",
    "\n",
    "\n",
    "\n",
    "# Extension questions\n",
    "\n",
    "***Q1.*** Investigate the use of the `.where()` function in the `numpy` package to add a column `hours_class` to `employees` containing the value 'low' when `fte_hours` is 0.5 or less and 'high' otherwise.\n",
    "\n",
    "**Hint** - Import `numpy` as `np`, and `.where()` will then be available as `np.where()`\n",
    "\n",
    "***\n",
    "    \n",
    "***Q2.*** Are there any `employees` with invalid `email` addresses?\n",
    "\n",
    "**Hint** - Count non-null `email` addresses that don't match a reasonable regex pattern for a valid email address\n",
    "\n",
    "***\n",
    "\n",
    "***Q3.*** How many of the `employees` serve on one or more `committees`?\n",
    "\n",
    "**Hints**\n",
    "\n",
    "* This requires only the `employees_committees` `DataFrame`\n",
    "* Think about distinct `employees`\n",
    "    \n",
    "***\n",
    "    \n",
    "***Q4.*** Get the full employee details (including committee name) of any committee members based in the Ukraine.\n",
    "\n",
    "**Attempt this question only after the lesson on joining, melting and pivoting `DataFrame`s on day 3**\n",
    "\n",
    "**Hints**\n",
    "    \n",
    "* This is a many-to-many join, so three `DataFrame`s will be involved: `employees`, `committees` and `employees_committees`\n",
    "* The `.query()` method lets you do all this in one line of code\n",
    "\n",
    "***\n",
    "\n",
    "***Q5.*** Obtain a table with column `start_month` containing the names of months and column `num_started` showing the number of `employees` who started in that month (in any year). The table should contain 12 rows, one for each month, and be ordered 'January', 'February', 'March' and so forth, in ascending calendar order.\n",
    "\n",
    "**Hints**\n",
    "    \n",
    "* Extracting both the `.month_name()` and `.month` from `start_date` might help here\n",
    "* We used `.assign()` to create the two new date feature columns before any subsequent operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
